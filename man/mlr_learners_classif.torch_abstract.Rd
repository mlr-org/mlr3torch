% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LearnerTorch.R
\name{mlr_learners_classif.torch_abstract}
\alias{mlr_learners_classif.torch_abstract}
\alias{LearnerClassifTorch}
\title{Abstract Base Class for a Torch Network}
\format{
\code{\link{R6Class}} inheriting from \code{\link{LearnerClassif}}, \code{\link{Learner}}.
}
\description{
This base class provides the basic functionality for training and prediction of a neural network.
All torch learners should inherit from the respective subclass.
To create a torch learner from a \code{\link{nn_module}}, use \code{\link{LearnerClassifTorch}} or \code{\link{LearnerRegrTorch}} instead.
}
\section{Construction}{

\code{LearnerClassifTorch$new(id, optimizer, loss, param_set, properties = NULL, packages = character(0), predict_types = c("response", "prob"), feature_types, man, label, callbacks = list())}
\itemize{
\item \code{id} :: \code{character(1)}\cr The id for the object.
\item \code{optimizer} :: (\code{\link{TorchOptimizer}})\cr
The optimizer for the model.
\item \code{loss} :: (\code{\link{TorchLoss}})\cr
The loss for the model.
\item \code{param_set} :: \code{paradox::ParamSet}\cr The parameter set.
\item \code{properties} :: (\code{character()})\cr
The properties for the learner, see \code{mlr_reflections$learner_properties}.
\item \code{packages} :: (\code{character()})\cr
The additional packages on which the learner depends. The packages \code{"torch"} and \code{"mlr3torch"} are automatically
added so do not have to be passed explicitly.
\item \code{predict_types} :: (\code{character()})\cr
The learner's predict types, see \code{mlr_reflections$learner_predict_types}.
The default is \code{"response"} and \code{"prob"}.
\item \code{feature_types} :: (\code{character()})\cr
The feature types the learner can deal with, see \code{mlr_reflections$task_feature_types}.
\item \code{man} :: (\code{character(1)})\cr
String in the format \verb{[pkg]::[topic]} pointing to a manual page for this object.
The referenced help package can be opened via method \verb{$help()}.
\item \code{label} :: (\code{character(1)})\cr
The label for the learner.
}
}

\section{State}{

The state is a list with elements \code{network}, \code{optimizer}, \code{loss_fn} and \code{callbacks}.
}

\section{Parameters}{

\itemize{
\item \code{batch_size} :: (\code{integer(1)})\cr
The batch size.
\item \code{epochs} :: \code{integer(1)}\cr
The number of epochs.
\item \code{device} :: \code{character(1)}\cr
The device. One of \code{"auto"}, \code{"cpu"}, or \code{"cuda"}.
\item \code{measures_train} :: \code{\link{Measure}} or \code{list()} of \code{\link{Measure}}s.
Measures to be evaluated during training.
\item \code{measures_valid} :: \code{\link{Measure}} or \code{list()} of \code{\link{Measure}}s.
Measures to be evaluated during validation.
\item \code{drop_last} :: \code{logical(1)}\cr
Whether to drop the last batch in each epoch during training. Default is \code{FALSE}.
\item \code{num_threads} :: \code{integer(1)}\cr
The number of threads (if \code{device} is \code{"cpu"}). Default is 1.
\item \code{shuffle} :: \code{logical(1)}\cr
Whether to shuffle the instances in the dataset. Default is \code{TRUE}.
\item \code{early_stopping_rounds} :: \code{integer(1)}\cr
How many rounds to wait for early stopping. The default is 0.
\item \code{seed} :: \code{integer(1)}\cr
The seed that is used during training. The value \code{seed + 1} is used during prediction.
If this is missing (default), a random seed is generated.
}

Additionally there are the parameters for the optimizer, the loss function and the callbacks.
\code{"opt."}, \code{"loss."} and \code{"cb.<callback id>"} respectively.
}

\section{Inheriting}{

When inheriting from this class, one should overload two, methods, namely the
\code{private$.network(task, param_vals)} and the \code{private$.dataset(task, param_vals)}.
The former should construct \code{\link[torch:nn_module]{torch::nn_module}} object for the given task and parameter values, while the latter
is responsible for creating a \code{\link[torch:dataset]{torch::dataset}}.
Note that the output of this network are expected to be the scores before the application of the final softmax
layer.

It is also possible to overwrite the private \verb{$.dataloader()} method, which otherwise calls \verb{$.dataset()} and
creates a dataloader from that dataset. When doing so, it is important to respect the parameter \code{shuffle}, because
this method is used to ceate the dataloader for prediction as well.

While it is possible to add parameters by specifying the \code{param_set} constructino argument, it is currently
not possible to change these parameters.
Note that none of the parameters provided in \code{param_set} can have an id that starts with \code{"loss."} or \code{"opt."}
as these are preserved for the dynamically constructed parameters of the optimizer and the loss function.

For a more general introduction on how to create a new learner, see the respective section in the
\href{https://mlr3book.mlr-org.com/extending.html#sec-extending-learners}{mlr3 book}.
}

\section{Fields}{

Fields inherited from \code{\link{LearnerClassif}} or \code{\link{LearnerRegr}} and
\itemize{
\item \code{network} :: (\code{\link[torch:nn_module]{nn_module()}})\cr
The network (only available after training).
\item \code{hist_train} :: \code{data.table}\cr
The trainig history.
\item \code{hist_valid} :: \code{data.table}\cr
The validation history.
}
}

\section{Methods}{
 Methods inherited from \code{\link{LearnerClassif}}, \code{\link{Learner}}.
}

\section{Internals}{

A \code{\link{ParamSetCollection}} is created that combines the \code{param_set} from the construction with the
default parameters obtained by \code{\link[=paramset_torchlearner]{paramset_torchlearner()}}, as well as the loss and optimizer parameter
(prefixed with \code{"loss."} and \code{"opt."} respectively.

Note that a deep clone of trained networks is currently not supported, because having a edge-case covering solution
for that requires to mess with torch internals that are currently not part of the torch API.
}

\seealso{
Other Learners: 
\code{\link{mlr_learners_classif.torch_featureless}}
}
\concept{Learners}
