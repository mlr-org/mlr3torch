% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/TorchCallback.R, R/CallbackTorch.R
\name{torch_callback}
\alias{torch_callback}
\alias{TorchCallback}
\title{Torch Callback}
\format{
\code{\link{R6Class}}
}
\usage{
torch_callback(
  id,
  param_set = NULL,
  name = paste0("CallbackTorch", capitalize(id)),
  on_begin = NULL,
  on_end = NULL,
  on_epoch_begin = NULL,
  on_before_validation = NULL,
  on_epoch_end = NULL,
  on_batch_begin = NULL,
  on_batch_end = NULL,
  on_after_backward = NULL,
  on_batch_valid_begin = NULL,
  on_batch_valid_end = NULL,
  public = NULL,
  private = NULL,
  active = NULL,
  parent_env = parent.frame()
)
}
\arguments{
\item{id}{(\code{character(1)})\cr`\cr
The id for the callbacks. Note that the ids of callbacks passted to a learner must be unique.}

\item{param_set}{(\code{ParamSet})\cr
The parameter set, if not present it is inferred from the initialize method.}

\item{name}{(\code{character(1)})\cr
The class name of the torch callback. Is set to \code{"CallbackTorch<Id>"} per default.
E.g. id \code{id} is \code{"custom"}, the name is set to \code{"CallbackTorchCustom"}.}

\item{on_begin, }{on_end, on_epoch_begin, on_before_validation, on_epoch_end, on_batch_begin, on_batch_end,
on_after_backward, on_batch_valid_begin, on_batch_valid_end (`function( )\cr
Function to execute at the given stage, see section \emph{Stages}.}

\item{public}{(\code{list()})\cr
Additional public fields to add to the callback.}

\item{private}{(\code{list()})\cr
Additional private fields to add to the callback.}

\item{active}{(\code{list()})\cr
Additional active fields to add to the callback.}

\item{parent_env}{(\code{environment()})\cr
The parent environment for the \code{\link{R6Class}}.}
}
\description{
Container objects for torch callbacks.
A \code{TorchCallback} wraps a \code{CallbackTorch}.
To conveniently retrieve a \code{\link{TorchCallback}}, use \code{\link{t_clbk}}.
It is an analogous construct to the constructs \code{\link{TorchOptimizer}} or \code{\link{TorchLoss}}.

Convenience function to create a custom callback for torch.
For more information on how to correctly implement a new callback, see \code{\link{CallbackTorch}}.
}
\section{Construction}{
 \code{TorchCallback$new(callback_generator, param_set = NULL, packages = NULL)}
\itemize{
\item \code{callback_generator} :: \code{\link{R6ClassGenerator}}\cr
The class generator for the callback that is being wrapped.
\item \code{param_set} :: \code{\link{ParamSet}}\cr
The parameter set of the callback. These values are passed as construction arguments to the wrapped
\code{\link{CallbackTorch}}. The default is \code{NULL} in which case the parameter set is inferred from the construction
arguments of the wrapped callbacks.
}
}

\section{Fields}{

\itemize{
\item \code{callback} :: \code{\link{R6ClassGenerator}}\cr
The class generator for the R6 callback.
\item \code{param_set} :: \code{\link{ParamSet}}\cr
The parameter set. Its values are passed to \verb{$get_callback()}.
}
}

\section{Methods}{

\itemize{
\item \code{get_callback()}\cr
() -> \code{CallbackTorch}
Initializes an instance of the class of the wrapped callback with the given parameter specification.
}
}

\section{Internals}{

It first creates an \code{\link{R6ClassGenerator}} that generates a \code{\link{CallbackTorch}} and when wraps this generator in a
\code{\link{TorchCallback}}.
}

\section{Stages}{

\itemize{
\item \code{begin} :: Run before the training loop begins.
\item \code{epoch_begin} :: Run he beginning of each epoch.
\item \code{before_validation} :: Run before each validation loop.
\item \code{batch_begin} :: Run before the forward call.
\item \code{after_backward} :: Run after the backward call.
\item \code{batch_end} :: Run after the optimizer step.
\item \code{batch_valid_begin} :: Run before the forward call in the validation loop.
\item \code{batch_valid_end} :: Run after the forward call in the validation loop.
\item \code{epoch_end} :: Run at the end of each epoch.
\item \code{end} :: Run at last, using \code{on.exit()}.
}
}

\seealso{
Other torch_wrapper: 
\code{\link{torch_loss}},
\code{\link{torch_optimizer}}
}
\concept{torch_wrapper}
