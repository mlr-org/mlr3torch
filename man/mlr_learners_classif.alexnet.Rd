% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LearnerClassifAlexNet.R
\name{mlr_learners_classif.alexnet}
\alias{mlr_learners_classif.alexnet}
\alias{LearnerClassifAlexNet}
\title{AlexNet Image Classifier}
\description{
Convolutional network for image classification.
}
\section{Dictionary}{

This \link{Learner} can be instantiated via the \link[mlr3misc:Dictionary]{dictionary} \link{mlr_learners} or with the associated sugar function \code{\link[=lrn]{lrn()}}:\preformatted{mlr_learners$get("classif.alexnet")
lrn("classif.alexnet")
}
}

\section{Meta Information}{

\itemize{
\item Task type: \dQuote{classif}
\item Predict Types: \dQuote{response}
\item Feature Types: \dQuote{imageuri}
\item Required Packages: \CRANpkg{mlr3}, \CRANpkg{mlr3torch}, \CRANpkg{torch}, \CRANpkg{torchvision}
}
}

\section{Parameters}{
\tabular{lllll}{
   Id \tab Type \tab Default \tab Levels \tab Range \cr
   epochs \tab integer \tab - \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   device \tab character \tab auto \tab auto, cpu, cuda \tab - \cr
   batch_size \tab integer \tab 16 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   keep_last_prediction \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   early_stopping_set \tab character \tab test \tab test, train \tab - \cr
   shuffle \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
   drop_last \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   valid_split \tab numeric \tab 0.33 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   num_threads \tab integer \tab 1 \tab  \tab \eqn{[1, \infty)}{[1, Inf)} \cr
   train_fn \tab untyped \tab - \tab  \tab - \cr
   valid_fn \tab untyped \tab - \tab  \tab - \cr
   augmentation \tab untyped \tab - \tab  \tab - \cr
   architecture \tab untyped \tab - \tab  \tab - \cr
   opt.lr \tab numeric \tab 0.001 \tab  \tab \eqn{[0, \infty)}{[0, Inf)} \cr
   opt.betas \tab untyped \tab c    , 0.9  , 0.999 \tab  \tab - \cr
   opt.eps \tab numeric \tab 1e-08 \tab  \tab \eqn{[1e-16, 1e-04]}{[1e-16, 1e-04]} \cr
   opt.weight_decay \tab numeric \tab 0 \tab  \tab \eqn{[0, 1]}{[0, 1]} \cr
   opt.amsgrad \tab logical \tab FALSE \tab TRUE, FALSE \tab - \cr
   loss.weight \tab untyped \tab - \tab  \tab - \cr
   loss.ignore_index \tab integer \tab - \tab  \tab \eqn{(-\infty, \infty)}{(-Inf, Inf)} \cr
   loss.reduction \tab character \tab mean \tab mean, sum \tab - \cr
   pretrained \tab logical \tab TRUE \tab TRUE, FALSE \tab - \cr
}
}

\section{Architecture}{

Calls \link[torchvision:model_alexnet]{torchvision::model_alexnet} from package \CRANpkg{torchvision} to load the
network architecture. If the parameter \code{pretrained == TRUE}, the learner is initialized
with pretrained weights and the final layer is replaced with an simple linear
output layer tailored to the task when the method \verb{$train()} is called.
}

\section{Optimizer}{

The following optimizers are supported and can be set during construction using the
\code{.optimizer} argument.
\itemize{
\item adadelta
\item adagrad
\item adam
\item asgd
\item lbfgs
\item rmsprop
\item rprop
\item sgd
}

Depending on \code{.optimizer}, the constructor arguments of the corresponding
\link[torch:optimizer]{optimizer} are dynamically set as parameters of the learner, prefixed by
"opt.".
The optimizer cannot be changed after the learner was constructed.
}

\section{Loss}{

For classificatoin tasks, the following lossses are supported and can be set during construction
using the \code{.loss} argument:
\itemize{
\item mse
}

The default is set to "cross_entropy". Depending on the loss the constructor arguments of the
corresponding loss funcction are dynamically set as parameters of the learner, prefixed by
"loss.", see section \emph{Parameters} for an example using the \code{.loss = "cross_entropy"}.
The loss function cannot be changed after the learner was constructed.
}

\examples{
if (requireNamespace("mlr3torch", quietly = TRUE) && requireNamespace("torch", quietly = TRUE) && requireNamespace("torchvision", quietly = TRUE)) {
  learner = mlr3::lrn("classif.alexnet")
  print(learner)

  # available parameters:
learner$param_set$ids()
}
}
\references{
Krizhevsky, Alex (2014).
\dQuote{One weird trick for parallelizing convolutional neural networks.}
\emph{arXiv preprint arXiv:1404.5997}.
}
\seealso{
\itemize{
\item \link[mlr3misc:Dictionary]{Dictionary} of \link[mlr3:Learner]{Learners}: \link[mlr3:mlr_learners]{mlr3::mlr_learners}.
\item \code{as.data.table(mlr_learners)} for a table of available \link[=Learner]{Learners} in the running session (depending on the loaded packages).
\item Chapter in the \href{https://mlr3book.mlr-org.com/}{mlr3book}: \url{https://mlr3book.mlr-org.com/basics.html#learners}
\item \CRANpkg{mlr3learners} for a selection of recommended learners.
\item \CRANpkg{mlr3cluster} for unsupervised clustering learners.
\item \CRANpkg{mlr3pipelines} to combine learners with pre- and postprocessing steps.
\item \CRANpkg{mlr3tuning} for tuning of hyperparameters, \CRANpkg{mlr3tuningspaces} for established default tuning spaces.
}
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3:LearnerClassif]{mlr3::LearnerClassif}} -> \code{\link[mlr3torch:LearnerClassifTorchAbstract]{mlr3torch::LearnerClassifTorchAbstract}} -> \code{LearnerClassifAlexNet}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{LearnerClassifAlexNet$new()}}
\item \href{#method-clone}{\code{LearnerClassifAlexNet$clone()}}
}
}
\if{html}{
\out{<details ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner">}\href{../../mlr3/html/Learner.html#method-base_learner}{\code{mlr3::Learner$base_learner()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format">}\href{../../mlr3/html/Learner.html#method-format}{\code{mlr3::Learner$format()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help">}\href{../../mlr3/html/Learner.html#method-help}{\code{mlr3::Learner$help()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict">}\href{../../mlr3/html/Learner.html#method-predict}{\code{mlr3::Learner$predict()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata">}\href{../../mlr3/html/Learner.html#method-predict_newdata}{\code{mlr3::Learner$predict_newdata()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print">}\href{../../mlr3/html/Learner.html#method-print}{\code{mlr3::Learner$print()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset">}\href{../../mlr3/html/Learner.html#method-reset}{\code{mlr3::Learner$reset()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train">}\href{../../mlr3/html/Learner.html#method-train}{\code{mlr3::Learner$train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerClassifTorchAbstract" data-id="build">}\href{../../mlr3torch/html/LearnerClassifTorchAbstract.html#method-build}{\code{mlr3torch::LearnerClassifTorchAbstract$build()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifAlexNet$new(.optimizer = "adam", .loss = "cross_entropy")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{.optimizer}}{(\code{character()})\cr
A character string containing the name of the optimizer.
Possible values are \code{torch_reflections$optimizer}.}

\item{\code{.loss}}{(\code{character()})\cr
A character string containing the name of the loss function
For possible values see \code{torch_reflections$loss}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifAlexNet$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
