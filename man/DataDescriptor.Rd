% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DataDescriptor.R
\name{DataDescriptor}
\alias{DataDescriptor}
\title{Data Descriptor}
\usage{
DataDescriptor(
  dataset,
  dataset_shapes,
  graph = NULL,
  .input_map = NULL,
  .pointer = NULL,
  .pointer_shape = NULL,
  clone_graph = TRUE
)
}
\arguments{
\item{dataset}{(\code{\link[torch:dataset]{torch::dataset}})\cr
The torch dataset.}

\item{dataset_shapes}{(named \code{list()} of \code{integer()}s)\cr
The shapes of the output.
Names are the elements of the list returned by the dataset.
First dimension must be \code{NA}.}

\item{graph}{(\code{\link{Graph}})\cr
The preprocessing graph.
If left \code{NULL}, no preprocessing is applied to the data and \code{.input_map}, \code{.pointer} and \code{.pointer_shape}
are inferred in case the dataset returns only one element.}

\item{.input_map}{(\code{character()})\cr
Character vector that must have the same length as the input of the graph.
Specifies how the data from the \code{dataset} is fed into the preprocessing graph.}

\item{.pointer}{(\code{character(2)} | \code{NULL})\cr
Indicating an element on which a model is. Points to an output channel within \code{graph}:
Element 1 is the \code{PipeOp}'s id and element 2 is that \code{PipeOp}'s output channel.}

\item{.pointer_shape}{(\code{integer} | \code{NULL})\cr
Shape of the output indicated by \code{.pointer}. Note that this is \strong{without} the batch dimension as opposed
to the \code{\link{ModelDescriptor}}. The reason is that the .pointer_shape refers to exactly one element and hence
has no batch dimension.}

\item{clone_graph}{(\code{logical(1)})\cr
Whether to clone the preprocessing graph.}
}
\description{
A data descriptor is a rather internal structure used in the \code{\link{lazy_tensor}} data type.
In essence it is an annotated \code{\link[torch:dataset]{torch::dataset}} and a preprocessing graph (consisting mosty of \code{\link{PipeOpModule}}
operators). The additional meta data (e.g. shapes) allows to preprocess \code{\link{lazy_tensors}} in an
\code{\link[mlr3pipelines:Graph]{mlr3pipelines::Graph}} just like any (non-lazy) data types.
}
\examples{
# Create a dataset
dsg = dataset(
  initialize = function() self$x = torch_randn(10, 3, 3),
  .getitem = function(i) self$x[i, ],
  .length = function() nrow(self$x)
)
ds = dsg()

# Create the preprocessing graph
po_module = po("module", module = function(x) torch_reshape(x, c(-1, 9)))
po_module$output
graph = as_graph(po_module)

# Create the data descriptor

dd = DataDescriptor(
  dataset = ds,
  dataset_shapes = list(x = c(NA, 3, 3)),
  graph = graph,
  .input_map = "x",
  .pointer = c("module", "output"),
  .pointer_shape = c(NA, 9)
)

# with no preprocessing
dd1 = DataDescriptor(ds, list(x = c(NA, 3, 3)))
}
\seealso{
ModelDescriptor, lazy_tensor
}
