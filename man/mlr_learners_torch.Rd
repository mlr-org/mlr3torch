% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LearnerTorch.R
\name{mlr_learners_torch}
\alias{mlr_learners_torch}
\alias{LearnerTorch}
\title{Base Class for Torch Learners}
\description{
This base class provides the basic functionality for training and prediction of a neural network.
All torch learners should inherit from this class.

It also allows to hook into the training loop via a callback mechanism.
}
\section{State}{

The state is a list with elements \code{network}, \code{optimizer}, \code{loss_fn}, \code{callbacks} and \code{seed}.
}

\section{Parameters}{

\itemize{
\item \code{batch_size} :: (\code{integer(1)})\cr
The batch size.
\item \code{epochs} :: \code{integer(1)}\cr
The number of epochs.
\item \code{device} :: \code{character(1)}\cr
The device. One of \code{"auto"}, \code{"cpu"}, or \code{"cuda"} or other values defined in \code{mlr_reflections$torch$devices}.
The value is initialized to \code{"auto"}, which will select \code{"cuda"} if possible and \code{"cpu"} otherwise.
\item \code{measures_train} :: \code{\link{Measure}} or \code{list()} of \code{\link{Measure}}s.
Measures to be evaluated during training.
\item \code{measures_valid} :: \code{\link{Measure}} or \code{list()} of \code{\link{Measure}}s.
Measures to be evaluated during validation.
\item \code{num_threads} :: \code{integer(1)}\cr
The number of threads for intraop pararallelization (if \code{device} is \code{"cpu"}).
This value is initialized to 1.
\item \code{shuffle} :: \code{logical(1)}\cr
Whether to shuffle the instances in the dataset. This value is initialized to \code{TRUE}.
\item \code{seed} :: \code{integer(1)} or \code{"random"}\cr
The seed that is used during training and prediction.
This value is initialized to \code{"random"}, which means that a random seed will be sampled at the beginning of the
training phase. This seed (either set or randomly sampled) is available via \verb{$model$seed} after training
and used during prediction.
Note that by setting the seed during the training phase this will mean that by default (i.e. when \code{seed} is
\code{"random"}), clones of the learner will use a different seed.
}

Additionally there are the parameters for the optimizer, the loss function and the callbacks.
They are prefixed with \code{"opt."}, \code{"loss."} and \code{"cb.<callback id>."} respectively.
}

\section{Inheriting}{

There are no seperate classes for classification and regression to inherit from.
Instead, the \code{task_type} must be specified  as a construction argument.
Currently, only classification and regression are supported.

When inheriting from this class, one should overload two private methods:
\itemize{
\item \code{.network(task, param_vals)}\cr
(\code{\link{Task}}, \code{list()}) -> \code{\link{nn_module}}\cr
Construct a \code{\link[torch:nn_module]{torch::nn_module}} object for the given task and parameter values, i.e. the neural network that
is trained by the learner.
For classification, the output of this network are expected to be the scores before the application of the
final softmax layer.
\item \code{.dataset(task, param_vals)}\cr
(\code{\link{Task}}, \code{list()}) -> \code{\link[torch:dataset]{torch::dataset}}\cr
Create the dataset for the task.
Must respect the parameter value of the device.
Moreover, one needs to pay attention respect the row ids of the provided task.
}

It is also possible to overwrite the private \code{.dataloader()} method instead of the \code{.dataset()} method.
Per default, a dataloader is constructed using the output from the \code{.dataset()} method.
\itemize{
\item \code{.dataloader(task, param_vals)}\cr
(\code{\link{Task}}, \code{list()}) -> \code{\link[torch:dataloader]{torch::dataloader}}\cr
Create a dataloader from the task.
Needs to respect at least \code{batch_size} and \code{shuffle} (otherwise predictions can be permuted).
}

To change the predict types, the private \code{.encode_prediction()} method can be overwritten:
\itemize{
\item \code{.encode_prediction(predict_tensor, task, param_vals)}\cr
(\code{\link{torch_tensor}}, \code{\link{Task}}, \code{list()}) -> \code{list()}\cr
Take in the raw predictions from \code{self$network} (\code{predict_tensor}) and encode them into a
format that can be converted to valid \code{mlr3} predictions using \code{\link[mlr3:as_prediction_data]{mlr3::as_prediction_data()}}.
This method must take \code{self$predict_type} into account.
}

While it is possible to add parameters by specifying the \code{param_set} construction argument, it is currently
not possible to remove existing parameters, i.e. those listed in section \emph{Parameters}.
None of the parameters provided in \code{param_set} can have an id that starts with \code{"loss."}, \verb{"opt.", or }"cb."`, as these are preserved for the dynamically constructed parameters of the optimizer, the loss function,
and the callbacks.
}

\seealso{
Other Learner: 
\code{\link{mlr_learners.alexnet}},
\code{\link{mlr_learners.mlp}},
\code{\link{mlr_learners.torch_featureless}},
\code{\link{mlr_learners_torch_image}},
\code{\link{mlr_learners_torch_model}}
}
\concept{Learner}
\section{Super class}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{LearnerTorch}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{network}}{(\code{\link[torch:nn_module]{nn_module()}})\cr
The network (only available after training).}

\item{\code{param_set}}{(\code{\link{ParamSet}})\cr
The parameter set}

\item{\code{history}}{(\code{\link{CallbackSetHistory}})\cr
Shortcut for \code{learner$model$callbacks$history}.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LearnerTorch-new}{\code{LearnerTorch$new()}}
\item \href{#method-LearnerTorch-clone}{\code{LearnerTorch$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerTorch-new"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerTorch-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerTorch$new(
  id,
  task_type,
  param_set,
  properties,
  man,
  label,
  feature_types,
  optimizer = NULL,
  loss = NULL,
  packages = NULL,
  predict_types = NULL,
  callbacks = list()
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{id}}{(\code{character(1)})\cr
The id for of the new object.}

\item{\code{task_type}}{(\code{character(1)})\cr
The task type.}

\item{\code{param_set}}{(\code{paradox::ParamSet})\cr
The parameter set.}

\item{\code{properties}}{(\code{character()})\cr
The properties of the object.
See \code{\link[=mlr_reflections]{mlr_reflections$learner_properties}} for available values.}

\item{\code{man}}{(\code{character(1)})\cr
String in the format \verb{[pkg]::[topic]} pointing to a manual page for this object.
The referenced help package can be opened via method \verb{$help()}.}

\item{\code{label}}{(\code{character(1)})\cr
Label for the new instance.}

\item{\code{feature_types}}{(\code{character()})\cr
The feature types.
See \code{\link[=mlr_reflections]{mlr_reflections$task_feature_types}} for available values.}

\item{\code{optimizer}}{(\code{NULL} or \code{\link{TorchOptimizer}})\cr
The optimizer to use for training.
Defaults to adam.}

\item{\code{loss}}{(\code{NULL} or \code{\link{TorchLoss}})\cr
The loss to use for training.
Defaults to MSE for regression and cross entropy for classification.}

\item{\code{packages}}{(\code{character()})\cr
The R packages this object depends on.}

\item{\code{predict_types}}{(\code{character()})\cr
The predict types.
See \code{\link[=mlr_reflections]{mlr_reflections$learner_predict_types}} for available values.
For regression, the default is \code{"response"}.
For classification, this defaults to \code{"response"} and \code{"prob"}.
To deviate from the defaults, it is necessary to overwrite the private \verb{$.encode_prediction()}
method, see section \emph{Inheriting}.}

\item{\code{callbacks}}{(\code{list()} of \code{\link{TorchCallback}}s)\cr
The callbacks to use for training.
Defaults to an empty\code{ list()}, i.e. no callbacks.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LearnerTorch-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LearnerTorch-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerTorch$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
