# Optimizers

The table below shows all optimizers that are available in `mlr3torch`:

| Key                                                                      | Label                                 |
|:-------------------------------------------------------------------------|:--------------------------------------|
| [adagrad](https://torch.mlverse.org/docs/reference/optim_ignite_adagrad) | Adaptive Gradient algorithm           |
| [adam](https://torch.mlverse.org/docs/reference/optim_ignite_adam)       | Adaptive Moment Estimation            |
| [adamw](https://torch.mlverse.org/docs/reference/optim_ignite_adamw)     | Decoupled Weight Decay Regularization |
| [rmsprop](https://torch.mlverse.org/docs/reference/optim_ignite_rmsprop) | Root Mean Square Propagation          |
| [sgd](https://torch.mlverse.org/docs/reference/optim_ignite_sgd)         | Stochastic Gradient Descent           |
