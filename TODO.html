<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>NA • mlr3torch</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="apple-touch-icon-60x60.png"><script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/Roboto-0.4.8/font.css" rel="stylesheet"><link href="deps/JetBrains_Mono-0.4.8/font.css" rel="stylesheet"><link href="deps/Roboto_Slab-0.4.8/font.css" rel="stylesheet"><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="NA"><meta property="og:image" content="https://mlr3torch.mlr-org.com/logo.svg"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="index.html">mlr3torch</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Unreleased version">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="reference/index.html">
    <span class="fa fa fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="nav-item">
  <a class="nav-link" href="news/index.html">Changelog</a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr3book.mlr-org.com">
    <span class="fa fa fa fa-link"></span>
     
    mlr3book
  </a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlr-org/mlr3torch">
    <span class="fa fa fa fa-github"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr3">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-title-body">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="logo.svg" class="logo" alt=""><h1>NA</h1>
      
    </div>


<p><strong>Learner</strong></p>
<ul><li><label><input type="checkbox" checked>LearnerClassifTorchModel</label></li>
<li><label><input type="checkbox" checked>LearnerClassifTorchAbstract</label></li>
<li><label><input type="checkbox" checked>paramset_torchlearner</label></li>
<li>[o] train_loop (not sure how to test this)</li>
<li><label><input type="checkbox" checked>torch_network_predict</label></li>
<li><label><input type="checkbox" checked>encode_prediction</label></li>
<li>[o] learner_torch_train (not sure how to test this)</li>
<li>[o] learner_torch_predict (not sure how to test this)</li>
</ul><p><strong>Callbacks</strong></p>
<ul class="task-list"><li><label><input type="checkbox" checked>CallbackSetProgress</label></li>
<li><label><input type="checkbox" checked>CallbackSetHistory</label></li>
<li><label><input type="checkbox" checked>torch_callback</label></li>
<li><label><input type="checkbox" checked>CallbackSet</label></li>
<li><label><input type="checkbox" checked>ContextTorch</label></li>
<li><label><input type="checkbox" checked>t_clbk</label></li>
</ul><p><strong>Graph</strong></p>
<ul class="task-list"><li><label><input type="checkbox">PipeOpTorch</label></li>
<li><label><input type="checkbox" checked>nn_graph</label></li>
<li><label><input type="checkbox" checked>ModelDescriptior</label></li>
<li><label><input type="checkbox" checked>print.ModelDescriptor</label></li>
<li><label><input type="checkbox" checked>model_descriptor_to_module</label></li>
<li><label><input type="checkbox" checked>model_descriptor_to_learner</label></li>
<li><label><input type="checkbox" checked>model_descriptor_union</label></li>
<li><label><input type="checkbox" checked>print.TorchIngressToken</label></li>
<li><label><input type="checkbox" checked>batchgetter_categ</label></li>
<li><label><input type="checkbox" checked>TorchIngressToken</label></li>
</ul><p><strong>Optimizer</strong></p>
<ul class="task-list"><li><label><input type="checkbox" checked>TorchOptimizer</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer.character</label></li>
<li><label><input type="checkbox" checked>mlr3torch_optimizers</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer.TorchOptimizer</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer.torch_optimizer_generator</label></li>
<li><label><input type="checkbox" checked>t_opt</label></li>
</ul><p><strong>Loss</strong></p>
<ul class="task-list"><li><label><input type="checkbox" checked>TorchLoss</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer.TorchLoss</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer.nn_loss</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer</label></li>
<li><label><input type="checkbox" checked>t_loss</label></li>
<li><label><input type="checkbox" checked>mlr3torch_losses</label></li>
<li><label><input type="checkbox" checked>as_torch_optimizer.character</label></li>
</ul><p><strong>Other</strong></p>
<ul class="task-list"><li><label><input type="checkbox" checked>argument_matcher</label></li>
<li><label><input type="checkbox">expect_pipeop_torch</label></li>
<li><label><input type="checkbox">avg_output_shape</label></li>
<li><label><input type="checkbox">po_register_env</label></li>
<li><label><input type="checkbox">Tiny Imagenet</label></li>
<li><label><input type="checkbox">inferps</label></li>
<li><label><input type="checkbox">register_po</label></li>
<li><label><input type="checkbox">check_measures</label></li>
<li><label><input type="checkbox">make_activation</label></li>
<li><label><input type="checkbox">register_mlr3</label></li>
<li><label><input type="checkbox">check_vector</label></li>
<li><label><input type="checkbox">conv_transpose_output_shape</label></li>
<li><label><input type="checkbox">conv_output_shape</label></li>
<li><label><input type="checkbox">lg</label></li>
<li><label><input type="checkbox">check_callbacks</label></li>
<li><label><input type="checkbox">load_task_tiny_imagenet</label></li>
<li><label><input type="checkbox">batchgetter_num</label></li>
<li><label><input type="checkbox">task_dataset</label></li>
<li><label><input type="checkbox" checked>unique_id</label></li>
<li><label><input type="checkbox">measure_prediction</label></li>
<li><label><input type="checkbox">toytask -&gt; this name sucks</label></li>
<li><label><input type="checkbox">register_mlr3pipelines</label></li>
<li><label><input type="checkbox" checked>imageuri</label></li>
</ul><p><strong>NNs</strong></p>
<ul class="task-list"><li><label><input type="checkbox">nn_merge_prod</label></li>
<li><label><input type="checkbox">nn_unsqueeze</label></li>
<li><label><input type="checkbox">nn_merge_cat</label></li>
<li><label><input type="checkbox">nn_squeeze</label></li>
<li><label><input type="checkbox">nn_merge_sum</label></li>
<li><label><input type="checkbox">nn_reshape</label></li>
</ul><p>Some notes:</p>
<ul><li>Should we enforce the “train” tag for Torch{Optimizer, Loss, Callback}, i.e. set it in the initialize method of LearnerTorch?</li>
<li><label><input type="checkbox">in learner construction ensure usage of “train” and “predict” parameters</label></li>
<li><label><input type="checkbox">Utility functions for save_torch_learner and load_torch_learner, this should also be called in callback checkpoint</label></li>
<li>Custom Backend for torch datases with hardcoded metadata, torchdatasets in suggests and not depends</li>
<li><label><input type="checkbox">Fix the dictionary issue for the learners and the tasks</label></li>
<li>ctx in intitiaalize self zuweisen: Dann ist klar dass das immer das gleiche Objekt ist</li>
<li>rename TorchLoss, TorchOptimizer, TorchCallback to e.g. TorchDescriptorLoss</li>
<li>images like in torchvision (not in inst but in tests)</li>
<li>assignment for imageuri</li>
<li>nano imagenet is pointless task, only one image per class. Rather use only two classes and distinguish between them in tests.</li>
<li>Conflict between lgr and progress</li>
<li>investigate caching of networks and datasets</li>
<li>Ensure that the names of the output of the dataloader correspond to the names of the network’s forward function Beware … inputs! Needs renaming some existing dataloaders and an informative error message</li>
<li>What happens if there are two ingress tokens but one of them returns an empty tensor?</li>
<li>add saving to callback checkpoint I.e. the dataset_num, dataset_img etc. need to have an argument “argname” or something</li>
<li>For tasks: Get a better task than nano_imagenet. Ideally one with images of different shape. Then remove it from the</li>
<li>cloning of pipeopmodule –&gt; adapt expect_deep_clone for torch</li>
<li>warn when cloning custom callbacks</li>
<li>tests with non-standard row ids</li>
<li>test all parameters from paramset_torchlearner (in the learner)</li>
<li>What exactly does torch_num_set_threads do? What exactly does it influence? Also note that the documentation says that it cannot be set on Mac</li>
<li>Maybe with deep learning code we should not only test on ubuntu, but also on windows and mac?</li>
<li>Create a with_xxx function that sets the torch seed, the normal seed and torch threads and unsets them afterwards</li>
<li><label><input type="checkbox">Some image tasks</label></li>
<li>Why did the initialize method with param_set = self$param_set work???</li>
<li>Use with_torch_manual_seed when available</li>
<li>save_ctx as callback for testing</li>
<li>How to clone LearnerTorchModel (When .network is the trained network (?), what happens when calling train twice ???) –&gt; Probably this learner should NOT be exported or it must be clearly documented how this learner behaves. We could address this by cloning but this would cost a lot of performance in every train call of a torch graph learner. Alternatively, the PipeOpTorchXXX objects could store the call to create the nn_module() instead of creating the nn_module() immediately.</li>
<li>What about the learner that takes in a module?</li>
</ul><p><strong>Other</strong> * Check how the output names are generated, when outputs of non-terminal nodes are used in “output_map” (“output_<id>_output.<channel>“)</channel></id></p>
<ul class="task-list"><li><label><input type="checkbox">Implement the torch methods with explicit parameters in the function so that we can better check whether a parameter from paramset_torchlearner is actually doing something</label></li>
</ul><p><strong>Test Coverage</strong> * run paramtest vs expect_paramset –&gt; decide for one and delete the other * [ ] Proper testing for torch learners: * don’t need the autotest as we don’t really test the learners. * Instead we need to that: * network is generated correctly from the parameters * deep cloning works * The callbacks, optimizer, and loss are correctly set * the dataloader generates the data correctly and matches the network structure. This includes checking that the parameters (device, batch_size and shuffle are used correctly). Need to be extendinble to future parameters like num_workers * [ ] Check that defaults and initial values are correctly used everywhere * [ ] Autotest should check that all parameters are tagged with train and predict etc. Generally determine usage of tags. * [ ] Run some tests on gpu * [ ] ensure proper use of tags in e.g. <code>param_set$get_values(tags = "train")</code> in expect_learner_torch * use meta device to test device placement * What happens if a pipeoptorch ingress gets 0 features? * test: Manual test: Classification and Regression, test that it works with selecting only one features (“mpg”) (is currently a bug) * add test for predict_newdata * name variables and test better * [ ] properly test the shapes_out() method of the pipeoptorch * [ ] Parameters must have default or tag required (?) * [ ] Check that mlr_pipeops can still be converted to dict * [ ] autotest for torch learner should ensure that optimizer and loss can be set in construction * [ ] Test that the defaults of the activation functions are correctly implemented * [ ] Properly refactor the test helpers (classes and modules etc) in other files and dont keep them in the tests. * [ ] Use the tests from mlr3pipelines for all the pipeops * [ ] Test the updated versions of the Descriptors * [ ] Deep clones of torch modules: -&gt; the function that checks for deep clones needs to skip some torch-specific stuff, e.g. the attribute “module” for nn modules, or “Optimizer” for optim_adam etc. * [ ] Test that the default values of the pipeops are correctly documented * Write expect_learner_torch that checks all the properties a torch learner has to satisfy * [ ] Meta tests for the functions / objects created for the tests (like PipeOpTorchDebug) * [ ] Parameter tests for callbacks * [ ] Test that all optimizers are working (closure issue for lbfgs) * [ ] Test that all losses are working * [ ] regr learners have mse and classif ce as default loss * [ ] remove unneeded test helper functions from mlr3pipelines * Rename the TorchLoss, TorchOptimizer, TorchCallback to TorchCallback, TorchOptimizer, TorchLoss. * mention that .dataset() must take row ids into account and add tests with reverse row ids for iris, mtcars, nano_imagenet, … * expect_learner_torch should test all private methods (like .network, .dataloader). Because all the learners are essentially the same (except for these methods) autotests don’t make sense. Instead we test the general training funtions once and then the .network and .dataloader for each object (and that they match each other, e.g. with respect to argument names of the network’s forward function) * Must be possible to randomly initialize a seed. This is desireable when resampling a nn as one might want to take the variance of the initialization into account (currently all resamplings would be run with the same initialization) * LearnerTorchModel: * Deep cloning of learner torch model is problematic. * calling <code>$train()</code> twice keeps training the network which we probably don’t want. * document somewhere that MPS device is not reprodicle with with_torch_manual_seed * Use lgr instead of cat etc., in general do a lot more logging</p>
<p><strong>Maybe</strong></p>
<p><strong>Documentation</strong></p>
<ul><li>Vignette</li>
</ul><p><strong>Once everything above is stable</strong></p>
<ul><li><p>How large are the resulting objects? We potentially store a whole lot of R6 classes in one learner. This might slow down stuff like batchtools CONSIDERABLY</p></li>
<li><p>use logging properly</p></li>
<li><p><label><input type="checkbox">Cloning of trained networks (requires new torch version)</label></p></li>
<li><p><label><input type="checkbox">Implement bundling</label></p></li>
<li><p>Possibility to keep the last validation prediction when doing train-predict to avoid doing this twice</p></li>
<li><p>create logo for package</p></li>
<li><p><label><input type="checkbox">Setup benchmark scripts that also run on GPU and run them at least once</label></p></li>
<li><p><label><input type="checkbox">Check which versions of the dependencies we require</label></p></li>
<li><p>create deep learning pipeop block called “paragraph”</p></li>
<li><p>add references to pkgdown website</p></li>
<li><p>Implement parameters “” and “early_stopping_rounds” and other parameters</p></li>
<li><p><label><input type="checkbox">general method for freezing and unfreezing parameters.</label></p></li>
<li><p><label><input type="checkbox">support the <code>weights</code> property for the learners.</label></p></li>
<li><p><label><input type="checkbox">Calling <code>benchmark()</code> and evaluate the jobs on different GPUs?</label></p></li>
<li><p><label><input type="checkbox">Check overhead on cpu and small batch sizes</label></p></li>
<li><p><label><input type="checkbox">Minimize the time the tests run!</label></p></li>
<li><p><label><input type="checkbox">Reset layer things</label></p></li>
<li><p>freezing as a callback</p></li>
<li><p>maybe integrate reset_last_layer into image learner, add property of learner that is something like “pretrained”</p></li>
<li><p><label><input type="checkbox">The tabnet learner (we then only have the mlp learner and tabnet but should be enough for the beginning)</label></p></li>
<li><p><label><input type="checkbox">The image learners</label></p></li>
<li><p>lr scheduler as callback</p></li>
<li><p>tensorboard callback</p></li>
<li><p><label><input type="checkbox">Add the learners from the attic and all image learners</label></p></li>
<li><p><label><input type="checkbox">Create {classif, regr}.torch_module learner to create custom torch learners (classif.torch did not really work because of the dataloader)</label></p></li>
<li><p><label><input type="checkbox">Implement early stopping</label></p></li>
</ul><p>Advertisement:</p>
<ul class="task-list"><li><label><input type="checkbox">The torch website features packages that build on top of torch</label></li>
<li><label><input type="checkbox">Maybe we can write a blogpost for the RStudio AI blog?</label></li>
</ul><p>Martin: * Names of network and ingress token in the case where there the <code>x</code> element of the dataloader has length 1?</p>


  </main></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Sebastian Fischer, Martin Binder.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

