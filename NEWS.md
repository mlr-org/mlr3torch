# mlr3torch dev

* perf: Use a faster image loader
* perf/BREAKING_CHANGE: Removed some optimizers for which no fast ('ignite') variant exists.
  For other optimizers, the old variant was replaced with the 'ignite' variant which
  leads to significantly faster training times.
* perf: The `jit_trace` parameter was added to `LearnerTorch` which when activated can lead
  to significantly faster training times
* BREAKING_CHANGE: The default optimizer is now AdamW instead of Adam
* feat: Add parameter `num_interop_threads` to `LearnerTorch`
* feat: Add adaptive average pooling
* feat: Added `n_layers` parameter to MLP
* BREAKING_CHANGE: The private `LearnerTorch$.dataloader()` method now operates no longer
  on the `task` but on the `dataset` generated by the private `LearnerTorch$.dataset()` method.
* feat: the `tensor_dataset` parameter was added, which allows to stack all batches
  at the beginning of training to make loading of batches afterwards faster.
* BREAKING_CHANGE: Early stopping now not uses `epochs - patience` for the internally tuned
  values instead of the trained number of `epochs` as it was before.
  Also, the improvement is calculated as the difference between the current and the best score,
  not the current and the previous score.
* feat: Added multimodal melanoma and cifar{10, 100} example tasks.
* feat: Added a callback to iteratively unfreeze parameters for finetuning.
* fix: torch learners can now be used with `AutoTuner`.
* feat: Added different learning rate schedulers as callbacks.
* feat: `PipeOpBlock` should no longer create ID clashes with other PipeOps in the graph (#260)
* fix: `device` is no longer part of the `dataset` which allows for parallel dataloading
  on GPUs.

# mlr3torch 0.1.2

* Don't use deprecated `data_formats` anymore
* Added `CallbackSetTB`, which allows logging that can be viewed by TensorBoard.

# mlr3torch 0.1.1

* fix(preprocessing): regarding the construction of some `PipeOps` such as `po("trafo_resize")`
  which failed in some cases.
* fix(ci): tests were not run in the CI
* fix(learner): `LearnerTabResnet` now works correctly
* Fix that tests were not run in the CI
* feat: added the `nn()` helper function to simplify the creation of neural network
  layers

# mlr3torch 0.1.0

* Initial CRAN release
