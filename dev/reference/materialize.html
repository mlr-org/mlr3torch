<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Materialize Lazy Tensor Columns — materialize • mlr3torch</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Roboto-0.4.9/font.css" rel="stylesheet"><link href="../deps/JetBrains_Mono-0.4.9/font.css" rel="stylesheet"><link href="../deps/Roboto_Slab-0.4.9/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><script src="../deps/MathJax-3.2.2/tex-chtml.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Materialize Lazy Tensor Columns — materialize"><meta name="description" content="This will materialize a lazy_tensor() or a data.frame() / list() containing – among other things –
lazy_tensor() columns.
I.e. the data described in the underlying DataDescriptors is loaded for the indices in the lazy_tensor(),
is preprocessed and then put unto the specified device.
Because not all elements in a lazy tensor must have the same shape, a list of tensors is returned by default.
If all elements have the same shape, these tensors can also be rbinded into a single tensor (parameter rbind)."><meta property="og:description" content="This will materialize a lazy_tensor() or a data.frame() / list() containing – among other things –
lazy_tensor() columns.
I.e. the data described in the underlying DataDescriptors is loaded for the indices in the lazy_tensor(),
is preprocessed and then put unto the specified device.
Because not all elements in a lazy tensor must have the same shape, a list of tensors is returned by default.
If all elements have the same shape, these tensors can also be rbinded into a single tensor (parameter rbind)."><meta property="og:image" content="https://mlr3torch.mlr-org.com/logo.svg"><meta name="robots" content="noindex"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">mlr3torch</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.1.0-9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-alt"></span> Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/callbacks.html">Custom Callbacks</a></li>
    <li><a class="dropdown-item" href="../articles/get_started.html">Get Started</a></li>
    <li><a class="dropdown-item" href="../articles/internals_pipeop_torch.html">Internals</a></li>
    <li><a class="dropdown-item" href="../articles/lazy_tensor.html">Lazy Tensor</a></li>
    <li><a class="dropdown-item" href="../articles/pipeop_torch.html">Defining an Architecture</a></li>
  </ul></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mlr3book.mlr-org.com"><span class="fa fa-link"></span> mlr3book</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlr-org/mlr3torch"><span class="fa fa-github"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/"><span class="fa fa-comments"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr3"><span class="fa fab fa-stack-overflow"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mlr-org.com/"><span class="fa fa-rss"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Materialize Lazy Tensor Columns</h1>
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr3torch/blob/main/R/materialize.R" class="external-link"><code>R/materialize.R</code></a></small>
      <div class="d-none name"><code>materialize.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>This will materialize a <code><a href="lazy_tensor.html">lazy_tensor()</a></code> or a <code><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame()</a></code> / <code><a href="https://rdrr.io/r/base/list.html" class="external-link">list()</a></code> containing – among other things –
<code><a href="lazy_tensor.html">lazy_tensor()</a></code> columns.
I.e. the data described in the underlying <code><a href="DataDescriptor.html">DataDescriptor</a></code>s is loaded for the indices in the <code><a href="lazy_tensor.html">lazy_tensor()</a></code>,
is preprocessed and then put unto the specified device.
Because not all elements in a lazy tensor must have the same shape, a list of tensors is returned by default.
If all elements have the same shape, these tensors can also be rbinded into a single tensor (parameter <code>rbind</code>).</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">materialize</span><span class="op">(</span><span class="va">x</span>, device <span class="op">=</span> <span class="st">"cpu"</span>, rbind <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'list'</span></span>
<span><span class="fu">materialize</span><span class="op">(</span><span class="va">x</span>, device <span class="op">=</span> <span class="st">"cpu"</span>, rbind <span class="op">=</span> <span class="cn">FALSE</span>, cache <span class="op">=</span> <span class="st">"auto"</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-x">x<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p>(any)<br>
The object to materialize.
Either a <code><a href="lazy_tensor.html">lazy_tensor</a></code> or a <code><a href="https://rdrr.io/r/base/list.html" class="external-link">list()</a></code> / <code><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame()</a></code> containing <code><a href="lazy_tensor.html">lazy_tensor</a></code> columns.</p></dd>


<dt id="arg-device">device<a class="anchor" aria-label="anchor" href="#arg-device"></a></dt>
<dd><p>(<code>character(1)</code>)<br>
The torch device.</p></dd>


<dt id="arg-rbind">rbind<a class="anchor" aria-label="anchor" href="#arg-rbind"></a></dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether to rbind the lazy tensor columns (<code>TRUE</code>) or return them as a list of tensors (<code>FALSE</code>).
In the second case, there is no batch dimension.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>(any)<br>
Additional arguments.</p></dd>


<dt id="arg-cache">cache<a class="anchor" aria-label="anchor" href="#arg-cache"></a></dt>
<dd><p>(<code>character(1)</code> or <code><a href="https://rdrr.io/r/base/environment.html" class="external-link">environment()</a></code> or <code>NULL</code>)<br>
Optional cache for (intermediate) materialization results.
Per default, caching will be enabled when the same dataset or data descriptor (with different output pointer)
is used for more than one lazy tensor column.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>(<code><a href="https://rdrr.io/r/base/list.html" class="external-link">list()</a></code> of <code><a href="lazy_tensor.html">lazy_tensor</a></code>s or a <code><a href="lazy_tensor.html">lazy_tensor</a></code>)</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Materializing a lazy tensor consists of:</p><ol><li><p>Loading the data from the internal dataset of the <code><a href="DataDescriptor.html">DataDescriptor</a></code>.</p></li>
<li><p>Processing these batches in the preprocessing <code><a href="https://mlr3pipelines.mlr-org.com/reference/Graph.html" class="external-link">Graph</a></code>s.</p></li>
<li><p>Returning the result of the <code><a href="https://mlr3pipelines.mlr-org.com/reference/PipeOp.html" class="external-link">PipeOp</a></code> pointed to by the <code><a href="DataDescriptor.html">DataDescriptor</a></code> (<code>pointer</code>).</p></li>
</ol><p>With multiple <code><a href="lazy_tensor.html">lazy_tensor</a></code> columns we can benefit from caching because:
a) Output(s) from the dataset might be input to multiple graphs.
b) Different lazy tensors might be outputs from the same graph.</p>
<p>For this reason it is possible to provide a cache environment.
The hash key for a) is the hash of the indices and the dataset.
The hash key for b) is the hash of the indices, dataset and preprocessing graph.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">lt1</span> <span class="op">=</span> <span class="fu"><a href="as_lazy_tensor.html">as_lazy_tensor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/torch_randn.html" class="external-link">torch_randn</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">materialize</span><span class="op">(</span><span class="va">lt1</span>, rbind <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1749 -0.6882 -0.2658</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6541  0.2850 -0.1029</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9486 -0.0943 -0.3079</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7667  1.0356  0.4322</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.3736 -0.2807 -0.0809</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.1788  0.9644  0.9528</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3776 -0.8124  1.5935</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.7875  1.1562  0.7218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5824  0.3756  0.2727</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2506  1.1150  2.9780</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{10,3} ]</span>
<span class="r-in"><span><span class="fu">materialize</span><span class="op">(</span><span class="va">lt1</span>, rbind <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[1]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1749</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.6882</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.2658</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[2]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6541</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2850</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1029</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[3]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9486</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.0943</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.3079</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[4]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7667</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.0356</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.4322</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[5]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.3736</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.2807</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.0809</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[6]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.1788</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9644</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9528</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[7]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3776</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.8124</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.5935</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[8]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.7875</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.1562</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[9]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5824</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3756</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2727</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[10]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2506</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.1150</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  2.9780</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="va">lt2</span> <span class="op">=</span> <span class="fu"><a href="as_lazy_tensor.html">as_lazy_tensor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/torch_randn.html" class="external-link">torch_randn</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">d</span> <span class="op">=</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/data.table.html" class="external-link">data.table</a></span><span class="op">(</span>lt1 <span class="op">=</span> <span class="va">lt1</span>, lt2 <span class="op">=</span> <span class="va">lt2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">materialize</span><span class="op">(</span><span class="va">d</span>, rbind <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1749 -0.6882 -0.2658</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6541  0.2850 -0.1029</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9486 -0.0943 -0.3079</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7667  1.0356  0.4322</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.3736 -0.2807 -0.0809</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.1788  0.9644  0.9528</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3776 -0.8124  1.5935</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.7875  1.1562  0.7218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5824  0.3756  0.2727</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2506  1.1150  2.9780</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{10,3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5655 -1.7281 -1.4185  1.7014</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.4636 -0.6829  2.2684 -0.7648</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.0484  0.2748  0.5523  0.2490</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5541 -0.6773  0.1771 -0.1763</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2727  0.2371  0.0948 -0.1212</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2887  0.1907 -2.2326 -1.4750</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5818 -0.1095 -1.4218  0.3193</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.3912  0.6072  0.5303  0.7094</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6184 -2.0417  0.6659 -2.0218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.0884  1.2816  1.4576  2.2832</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{10,4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">materialize</span><span class="op">(</span><span class="va">d</span>, rbind <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[1]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1749</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.6882</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.2658</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[2]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6541</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2850</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1029</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[3]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9486</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.0943</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.3079</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[4]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7667</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.0356</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.4322</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[5]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.3736</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.2807</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.0809</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[6]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.1788</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9644</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.9528</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[7]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3776</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.8124</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.5935</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[8]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.7875</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.1562</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[9]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5824</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3756</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2727</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt1[[10]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2506</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.1150</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  2.9780</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{3} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[1]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5655</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.7281</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.4185</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.7014</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[2]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.4636</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.6829</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  2.2684</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.7648</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[3]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.0484</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2748</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5523</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2490</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[4]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5541</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.6773</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.1771</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1763</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[5]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2727</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2371</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.0948</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1212</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[6]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.2887</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.1907</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -2.2326</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.4750</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[7]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5818</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.1095</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.4218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3193</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[8]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -0.3912</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6072</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5303</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.7094</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[9]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6184</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -2.0417</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.6659</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -2.0218</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $lt2[[10]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> torch_tensor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> -1.0884</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.2816</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  1.4576</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  2.2832</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ CPUFloatType{4} ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sebastian Fischer, Martin Binder.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer></div>





  </body></html>

